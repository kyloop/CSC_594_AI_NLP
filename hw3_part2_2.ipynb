{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.book import text2, text5, text6\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "#Part-1: Create a text by combining NLTK's text2 (Sense and Sensibility by Jane Austen), \n",
    "#text5 (Chat Corpus) and text6 (Monty Python and the Holy Grail).\n",
    "unigrams = list(text2)+list(text5)+list(text6) #Combine unigrams\n",
    "bigrams = list(nltk.bigrams(unigrams))\n",
    "vocabulary = set(unigrams)\n",
    "cfd=nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "#Concept to  Laplace smoothing\n",
    "#[(1 + cfd[a][b])/(len(vocabulary)+cfd[a].N()) for a,b in nltk.bigrams(unigrams)]\n",
    "cpd_laplace = nltk.ConditionalProbDist(cfd, nltk.LaplaceProbDist, \n",
    "                                       bins=len(vocabulary))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(cfdist, word, num, selection):\n",
    "    #Case 0 -- select the next word with the highest/max frequency.\n",
    "    if selection == 0:#User pick the selection = 0 (= Max(Probability) selection)\n",
    "        for i in range(num):\n",
    "            print(word, end=' ')\n",
    "            if word==\".\": break #Break the loop if next word is a period (i.e. \".\")            \n",
    "            word = cfdist[word].max() #Find the word which has the highest probability in the input cfd            \n",
    "            #Break the loop when there is NO next word from Conditional distribution \n",
    "            if len(cfdist[word].samples()) == 0: break\n",
    "    #User pick the selection = 1 (= Randomly selection)\n",
    "    elif selection == 1: \n",
    "        for i in range(num):\n",
    "            print(word, end=' ')\n",
    "            if word==\".\":break #Break the loop if next word is a period (i.e. \".\")\n",
    "            #Randomly Select the next words which are originaly binded to word1 in cfd (word1, word2) \n",
    "            word = random.choice(list(cfdist[word].samples()))\n",
    "            #Break the loop when there is NO next word from Conditional distribution \n",
    "            if len(cfdist[word].samples()) == 0:break\n",
    "    #User pick the selection = 2 (= probabilistically selection)            \n",
    "    elif selection == 2: \n",
    "        for i in range(num):\n",
    "            print(word, end=\" \")\n",
    "            if word==\".\":break #Break the loop if next word is a period (i.e. \".\")\n",
    "            cumulative_probability=0.0 #initialize cumulative probability variable\n",
    "            #Create probablility list from entrie set of vocabulary (Next word) that \n",
    "            #associated the word1(i.e. word1,Next word) after Adding 1 Laplace smoothing \n",
    "            probability_lst= [cpd_laplace[word].prob(w) for w in vocabulary]\n",
    "            random_pt = random.uniform(0,1) #Random generate a float between 0and 1 from uniform distribution\n",
    "            #Iterating the entire set of vocabulary and its probability associated with word1\n",
    "            for next_word, prob in zip(vocabulary, probability_lst):\n",
    "                cumulative_probability += prob #adding up next words'probability until reach the condition below\n",
    "                #if cumulative Probability is larger than the float generated above, break the iteration\n",
    "                if cumulative_probability > random_pt: \n",
    "                    word = next_word #then next word becomes word to print next\n",
    "                    break\n",
    "    else:\n",
    "        #Wrong selection other than 0,1,2\n",
    "        print(\"Wrong input selection value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Generate sentences output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have been so much more than she had been so much more than she had been so much more than she had been so much more than she had been so much more than she had been so much more than she had been so much more than she had been so much more than she had been so much more than she had been so much more than she had been so much more than she had been so much more than she had been so much more than she had been so much more than she had "
     ]
    }
   ],
   "source": [
    "#Selection = 0\n",
    "generate_model(cpd_laplace, \"We\", 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We dance ... thot it smells like circumstances make comparisons , Galahad . "
     ]
    }
   ],
   "source": [
    "#Selection = 1\n",
    "generate_model(cpd_laplace, \"We\", 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We metal raarrrrrr somehow forlorn paid WITHOUT canadaian worries U820 Mind Book stops team pack L biters Me ladis surpass byes treasured censured LOUDER consultant awwwwwwwwww project respecting star AHAHHA Oak Howdy hgey howl outgrown malevolence U37 blueberry tranquillity principal pretty foresight minutely halves preferred hiding liveliness possessions Soon comprehended discarded ;\"-- litening raptures Always chatty connect whos Daveeee innocently already ye chickened confusion court uncouth )-- Chagrined coem ?????? main voluntary overcame sure chip pumpkin Jones itch qualified happier drinking intermission cops excuuuuuuse modest ((((((((((((((( Erm strangeness . . . unlover sang easy goodness !!!!!! ENCHANTER headache coach smirks judge holdin "
     ]
    }
   ],
   "source": [
    "#Selection = 2\n",
    "generate_model(cpd_laplace, \"We\", 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong input selection value\n"
     ]
    }
   ],
   "source": [
    "generate_model(cpd_laplace, \"We\", 40, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
